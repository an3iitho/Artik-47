{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Artik 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17785751376919860730\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2255906407\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17428994458375981652\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import neighbors\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import *\n",
    "# import catboost as ctb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH_RESULTS = f'~\\Documents\\Artik_47\\Artik-47\\results\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01 06:00:00</td>\n",
       "      <td>1.95817</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-01 06:30:00</td>\n",
       "      <td>1.95815</td>\n",
       "      <td>1651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-01 07:00:00</td>\n",
       "      <td>1.95824</td>\n",
       "      <td>1352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-01 07:30:00</td>\n",
       "      <td>1.95822</td>\n",
       "      <td>1722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-01 08:00:00</td>\n",
       "      <td>1.95852</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193895</th>\n",
       "      <td>2022-07-13 03:30:00</td>\n",
       "      <td>1.18863</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193896</th>\n",
       "      <td>2022-07-13 04:00:00</td>\n",
       "      <td>1.18813</td>\n",
       "      <td>1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193897</th>\n",
       "      <td>2022-07-13 04:30:00</td>\n",
       "      <td>1.18794</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193898</th>\n",
       "      <td>2022-07-13 05:00:00</td>\n",
       "      <td>1.18797</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193899</th>\n",
       "      <td>2022-07-13 05:30:00</td>\n",
       "      <td>1.18774</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Time    Close  Volume\n",
       "0      2007-01-01 06:00:00  1.95817    1728\n",
       "1      2007-01-01 06:30:00  1.95815    1651\n",
       "2      2007-01-01 07:00:00  1.95824    1352\n",
       "3      2007-01-01 07:30:00  1.95822    1722\n",
       "4      2007-01-01 08:00:00  1.95852    1729\n",
       "...                    ...      ...     ...\n",
       "193895 2022-07-13 03:30:00  1.18863     596\n",
       "193896 2022-07-13 04:00:00  1.18813    1522\n",
       "193897 2022-07-13 04:30:00  1.18794    1852\n",
       "193898 2022-07-13 05:00:00  1.18797    1404\n",
       "193899 2022-07-13 05:30:00  1.18774    1175\n",
       "\n",
       "[193900 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbpusd = pd.read_csv(f'~\\Documents\\Artik_47\\Artik-47\\data\\GBPUSD_M30.csv', sep='\\t', parse_dates=['Time'])\n",
    "\n",
    "#Just for close values as objetive\n",
    "gbpusd = gbpusd[['Time', 'Close', 'Volume']]\n",
    "gbpusd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>193900.000000</td>\n",
       "      <td>193900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.513250</td>\n",
       "      <td>5233.197968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.215370</td>\n",
       "      <td>11369.920694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.142930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.322348</td>\n",
       "      <td>1562.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517765</td>\n",
       "      <td>2935.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.613150</td>\n",
       "      <td>5508.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.114250</td>\n",
       "      <td>556867.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Close         Volume\n",
       "count  193900.000000  193900.000000\n",
       "mean        1.513250    5233.197968\n",
       "std         0.215370   11369.920694\n",
       "min         1.142930       1.000000\n",
       "25%         1.322348    1562.000000\n",
       "50%         1.517765    2935.000000\n",
       "75%         1.613150    5508.000000\n",
       "max         2.114250  556867.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbpusd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def shift_col(df, col_name, n):\n",
    "    \"\"\"\n",
    "    Shift column in df, n times\n",
    "    :param df: dataframe\n",
    "    :param col_name: str\n",
    "    :param n: int\n",
    "    :return: dateframe, list columns with shift\n",
    "    \"\"\"\n",
    "    list_shift = []\n",
    "    for i in range(1,n):\n",
    "        new_name_col = col_name + '_' + str(i)\n",
    "        df[new_name_col] = df[col_name].shift(i)\n",
    "        list_shift.append(new_name_col)\n",
    "\n",
    "    return df, list_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close_1</th>\n",
       "      <th>Close_2</th>\n",
       "      <th>Close_3</th>\n",
       "      <th>Close_4</th>\n",
       "      <th>Close_5</th>\n",
       "      <th>var_last_val</th>\n",
       "      <th>Volume_1</th>\n",
       "      <th>Volume_2</th>\n",
       "      <th>Volume_3</th>\n",
       "      <th>Volume_4</th>\n",
       "      <th>Volume_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-01-01 08:30:00</td>\n",
       "      <td>1.95877</td>\n",
       "      <td>1.95852</td>\n",
       "      <td>1.95822</td>\n",
       "      <td>1.95824</td>\n",
       "      <td>1.95815</td>\n",
       "      <td>1.95817</td>\n",
       "      <td>2.245000e-08</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>1728.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-01-01 09:00:00</td>\n",
       "      <td>1.95882</td>\n",
       "      <td>1.95877</td>\n",
       "      <td>1.95852</td>\n",
       "      <td>1.95822</td>\n",
       "      <td>1.95824</td>\n",
       "      <td>1.95815</td>\n",
       "      <td>6.745000e-08</td>\n",
       "      <td>1524.0</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>1651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007-01-01 09:30:00</td>\n",
       "      <td>1.95883</td>\n",
       "      <td>1.95882</td>\n",
       "      <td>1.95877</td>\n",
       "      <td>1.95852</td>\n",
       "      <td>1.95822</td>\n",
       "      <td>1.95824</td>\n",
       "      <td>8.018000e-08</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1524.0</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>1352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007-01-01 10:00:00</td>\n",
       "      <td>1.95840</td>\n",
       "      <td>1.95883</td>\n",
       "      <td>1.95882</td>\n",
       "      <td>1.95877</td>\n",
       "      <td>1.95852</td>\n",
       "      <td>1.95822</td>\n",
       "      <td>6.897000e-08</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1524.0</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>1722.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2007-01-01 10:30:00</td>\n",
       "      <td>1.95823</td>\n",
       "      <td>1.95840</td>\n",
       "      <td>1.95883</td>\n",
       "      <td>1.95882</td>\n",
       "      <td>1.95877</td>\n",
       "      <td>1.95852</td>\n",
       "      <td>3.837000e-08</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1524.0</td>\n",
       "      <td>1729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193895</th>\n",
       "      <td>2022-07-13 03:30:00</td>\n",
       "      <td>1.18863</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>1.18834</td>\n",
       "      <td>1.18883</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>1.18866</td>\n",
       "      <td>4.823000e-08</td>\n",
       "      <td>448.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>979.0</td>\n",
       "      <td>2881.0</td>\n",
       "      <td>2673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193896</th>\n",
       "      <td>2022-07-13 04:00:00</td>\n",
       "      <td>1.18813</td>\n",
       "      <td>1.18863</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>1.18834</td>\n",
       "      <td>1.18883</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>4.910000e-08</td>\n",
       "      <td>596.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>979.0</td>\n",
       "      <td>2881.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193897</th>\n",
       "      <td>2022-07-13 04:30:00</td>\n",
       "      <td>1.18794</td>\n",
       "      <td>1.18813</td>\n",
       "      <td>1.18863</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>1.18834</td>\n",
       "      <td>1.18883</td>\n",
       "      <td>9.878000e-08</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193898</th>\n",
       "      <td>2022-07-13 05:00:00</td>\n",
       "      <td>1.18797</td>\n",
       "      <td>1.18794</td>\n",
       "      <td>1.18813</td>\n",
       "      <td>1.18863</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>1.18834</td>\n",
       "      <td>1.352700e-07</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193899</th>\n",
       "      <td>2022-07-13 05:30:00</td>\n",
       "      <td>1.18774</td>\n",
       "      <td>1.18797</td>\n",
       "      <td>1.18794</td>\n",
       "      <td>1.18813</td>\n",
       "      <td>1.18863</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>1.696800e-07</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193895 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ds    Close  Close_1  Close_2  Close_3  Close_4  \\\n",
       "5      2007-01-01 08:30:00  1.95877  1.95852  1.95822  1.95824  1.95815   \n",
       "6      2007-01-01 09:00:00  1.95882  1.95877  1.95852  1.95822  1.95824   \n",
       "7      2007-01-01 09:30:00  1.95883  1.95882  1.95877  1.95852  1.95822   \n",
       "8      2007-01-01 10:00:00  1.95840  1.95883  1.95882  1.95877  1.95852   \n",
       "9      2007-01-01 10:30:00  1.95823  1.95840  1.95883  1.95882  1.95877   \n",
       "...                    ...      ...      ...      ...      ...      ...   \n",
       "193895 2022-07-13 03:30:00  1.18863  1.18885  1.18834  1.18883  1.18885   \n",
       "193896 2022-07-13 04:00:00  1.18813  1.18863  1.18885  1.18834  1.18883   \n",
       "193897 2022-07-13 04:30:00  1.18794  1.18813  1.18863  1.18885  1.18834   \n",
       "193898 2022-07-13 05:00:00  1.18797  1.18794  1.18813  1.18863  1.18885   \n",
       "193899 2022-07-13 05:30:00  1.18774  1.18797  1.18794  1.18813  1.18863   \n",
       "\n",
       "        Close_5  var_last_val  Volume_1  Volume_2  Volume_3  Volume_4  \\\n",
       "5       1.95817  2.245000e-08    1729.0    1722.0    1352.0    1651.0   \n",
       "6       1.95815  6.745000e-08    1524.0    1729.0    1722.0    1352.0   \n",
       "7       1.95824  8.018000e-08    1565.0    1524.0    1729.0    1722.0   \n",
       "8       1.95822  6.897000e-08    1704.0    1565.0    1524.0    1729.0   \n",
       "9       1.95852  3.837000e-08    1643.0    1704.0    1565.0    1524.0   \n",
       "...         ...           ...       ...       ...       ...       ...   \n",
       "193895  1.18866  4.823000e-08     448.0     796.0     979.0    2881.0   \n",
       "193896  1.18885  4.910000e-08     596.0     448.0     796.0     979.0   \n",
       "193897  1.18883  9.878000e-08    1522.0     596.0     448.0     796.0   \n",
       "193898  1.18834  1.352700e-07    1852.0    1522.0     596.0     448.0   \n",
       "193899  1.18885  1.696800e-07    1404.0    1852.0    1522.0     596.0   \n",
       "\n",
       "        Volume_5  \n",
       "5         1728.0  \n",
       "6         1651.0  \n",
       "7         1352.0  \n",
       "8         1722.0  \n",
       "9         1729.0  \n",
       "...          ...  \n",
       "193895    2673.0  \n",
       "193896    2881.0  \n",
       "193897     979.0  \n",
       "193898     796.0  \n",
       "193899     448.0  \n",
       "\n",
       "[193895 rows x 13 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = gbpusd.copy()\n",
    "df = df.rename(columns={'Time':'ds'})\n",
    "\n",
    "#Shift last x values\n",
    "last_x = 6\n",
    "\n",
    "df, list_shift = shift_col(df, 'Close', last_x)\n",
    "\n",
    "#Variance of shift values\n",
    "df['var_last_val'] = df[list_shift].var(axis=1)\n",
    "\n",
    "#Shift volume because is impossible to have on time\n",
    "df, _ = shift_col(df, 'Volume', last_x)\n",
    "df = df.drop(columns=['Volume'])\n",
    "\n",
    "df = df.dropna()\n",
    "df#.iloc[:,2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.30    7108\n",
       "1.56    6741\n",
       "1.29    6642\n",
       "1.31    6331\n",
       "1.61    5869\n",
       "1.60    5844\n",
       "1.55    5692\n",
       "1.59    5085\n",
       "1.54    4996\n",
       "1.32    4687\n",
       "Name: Close, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the support and resistance\n",
    "\n",
    "#Top most frequent values with only 3 decimals\n",
    "df['Close'].astype(str).str[:4].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (129909, 11), X_test: (63986, 11), y_train:(129909,), y_test:(63986,)\n"
     ]
    }
   ],
   "source": [
    "#Spit\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,2:].values, df.iloc[:,1].values, test_size=0.33, shuffle=False)\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}, y_train:{y_train.shape}, y_test:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ML  version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def backtest_regression(model_name, fecha_inicio, fecha_fin, data, cutoff, retrain_days, t_scaler, n_pca, params=None):\n",
    "    print(\"from: \", fecha_inicio, \" to: \", fecha_fin)\n",
    "\n",
    "    #Primer entreno\n",
    "    mask = (data.ds < (fecha_inicio - timedelta(days=cutoff)))\n",
    "    train = data.loc[mask]\n",
    "\n",
    "    train = train.drop(columns=['ds'])\n",
    "\n",
    "    val_reales = np.array([])\n",
    "    val_pred = np.array([])\n",
    "    val_fechas = np.array([])\n",
    "\n",
    "    # Divide en variables de entrada y salida\n",
    "    X, y = train.values[:, 1:], train.values[:, 0].astype('float64')\n",
    "\n",
    "    #Scalers\n",
    "    if(t_scaler=='MinMaxScaler'):\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        X = scaler.fit_transform(X)\n",
    "    elif(t_scaler=='StandardScaler'):\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "    elif(t_scaler=='RobustScaler'):\n",
    "        scaler = RobustScaler(quantile_range=(0, 95.0))\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "    #PCA\n",
    "    if (type(n_pca) == int):\n",
    "        pca = PCA(n_components=n_pca)\n",
    "        X = pca.fit_transform(X)\n",
    "\n",
    "    #Crea el modelo\n",
    "    model = eval(model_name + \"()\")\n",
    "\n",
    "    #Agrega parametros\n",
    "    if(params!=None):\n",
    "        model.set_params(**params)\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "    pbar = tqdm(total=(fecha_fin-fecha_inicio).days+1)\n",
    "    fecha_index = fecha_inicio\n",
    "    while(fecha_index <= fecha_fin):\n",
    "        print(fecha_index)\n",
    "        # if(fecha_index.weekday() in retrain_days):\n",
    "        #\n",
    "        #     #Re entreno\n",
    "        #     mask = (data.ds < (fecha_index - timedelta(days=cutoff)))\n",
    "        #     train = data.loc[mask]\n",
    "        #     #print(\"Train: \\n\", train.iloc[:,0:6], \"\\n\")\n",
    "        #     train = train.drop(columns=['ds'])\n",
    "        #\n",
    "        #     # Divide en variables de entrada y salida\n",
    "        #     X, y = train.values[:, 1:], train.values[:, 0].astype('float64')\n",
    "        #\n",
    "        #     #Scalers\n",
    "        #     if(t_scaler=='MinMaxScaler'):\n",
    "        #         scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        #         X = scaler.fit_transform(X)\n",
    "        #     elif(t_scaler=='StandardScaler'):\n",
    "        #         scaler = StandardScaler()\n",
    "        #         X = scaler.fit_transform(X)\n",
    "        #     elif(t_scaler=='RobustScaler'):\n",
    "        #         scaler = RobustScaler(quantile_range=(0, 95.0))\n",
    "        #         X = scaler.fit_transform(X)\n",
    "        #\n",
    "        #     #PCA\n",
    "        #     if (type(n_pca) == int):\n",
    "        #         pca = PCA(n_components=n_pca)\n",
    "        #         X = pca.fit_transform(X)\n",
    "        #\n",
    "        #     model = eval(model_name + \"()\")\n",
    "        #\n",
    "        #     if(params!=None):\n",
    "        #         model.set_params(**params)\n",
    "        #\n",
    "        #     model.fit(X, y)\n",
    "\n",
    "        mask = (data.ds >= fecha_index) & (data.ds <= fecha_index + timedelta(hours=23))\n",
    "        to_pred = data.loc[mask]\n",
    "        if not(to_pred.empty):\n",
    "\n",
    "            val_fechas = np.append(val_fechas, to_pred.iloc[:,0].tolist())\n",
    "            #print(\"to_pred: \", to_pred.values)\n",
    "            to_pred = to_pred.drop(columns=['ds'])\n",
    "            # Divide en variables de entrada y salida\n",
    "            X, y = to_pred.values[:, 1:], to_pred.values[:, 0].astype('float64')\n",
    "\n",
    "            #Scalers\n",
    "            if((t_scaler=='MinMaxScaler') or (t_scaler=='StandardScaler') or (t_scaler=='RobustScaler')):\n",
    "                X = scaler.transform(X)\n",
    "\n",
    "            #PCA\n",
    "            if (type(n_pca) == int):\n",
    "                X = pca.transform(X)\n",
    "\n",
    "            y_hat = model.predict(X)\n",
    "\n",
    "            val_reales = np.append(val_reales, y)\n",
    "            val_pred = np.append(val_pred, y_hat)\n",
    "\n",
    "        fecha_index = fecha_index + timedelta(minutes=30)\n",
    "        pbar.update(1)\n",
    "\n",
    "    resultados = pd.DataFrame({'fechas':val_fechas, 'val_reales':val_reales, 'val_pred':val_pred})\n",
    "    pbar.close()\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Fecha inicial\n",
    "inicial_date = '01/01/2008 00:00:00'\n",
    "inicial_date = datetime.strptime(inicial_date, '%d/%m/%Y %H:%M:%S')\n",
    "#Fecha final\n",
    "end_date = '02/01/2008 23:00:00'\n",
    "end_date = datetime.strptime(end_date, '%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "#Nombre experimiento\n",
    "NOM_EXP = 'artik47_ML'\n",
    "\n",
    "#Variables generales de los modelos\n",
    "retrain_days = [3, 6]    #Monday is 0 and Sunday is 6\n",
    "cutoff = 0         #Dias atras del index que se toman para entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---> RandomForest <--- hora inicio: 2022-10-01 22:16:45.791675\n",
      "Parametros:  {'n_jobs': 4}  scaler:  False  pca:  False\n",
      "RandomForest_artik47_ML_2022_10_01-22_16.csv\n",
      "from:  2008-01-01 00:00:00  to:  2008-01-02 23:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:00, 27.21it/s]               \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01 00:00:00\n",
      "2008-01-01 00:30:00\n",
      "2008-01-01 01:00:00\n",
      "2008-01-01 01:30:00\n",
      "2008-01-01 02:00:00\n",
      "2008-01-01 02:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6it [00:00, 27.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "10it [00:00, 27.80it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01 03:00:00\n",
      "2008-01-01 03:30:00\n",
      "2008-01-01 04:00:00\n",
      "2008-01-01 04:30:00\n",
      "2008-01-01 05:00:00\n",
      "2008-01-01 05:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "14it [00:00, 27.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "17it [00:00, 27.76it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01 06:00:00\n",
      "2008-01-01 06:30:00\n",
      "2008-01-01 07:00:00\n",
      "2008-01-01 07:30:00\n",
      "2008-01-01 08:00:00\n",
      "2008-01-01 08:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "20it [00:00, 27.63it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01 09:00:00\n",
      "2008-01-01 09:30:00\n",
      "2008-01-01 10:00:00\n",
      "2008-01-01 10:30:00\n",
      "2008-01-01 11:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:00, 27.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "26it [00:00, 26.32it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01 11:30:00\n",
      "2008-01-01 12:00:00\n",
      "2008-01-01 12:30:00\n",
      "2008-01-01 13:00:00\n",
      "2008-01-01 13:30:00\n",
      "2008-01-01 14:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "29it [00:01, 26.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "32it [00:01, 26.77it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01 14:30:00\n",
      "2008-01-01 15:00:00\n",
      "2008-01-01 15:30:00\n",
      "2008-01-01 16:00:00\n",
      "2008-01-01 16:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "35it [00:01, 25.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "38it [00:01, 24.25it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01 17:00:00\n",
      "2008-01-01 17:30:00\n",
      "2008-01-01 18:00:00\n",
      "2008-01-01 18:30:00\n",
      "2008-01-01 19:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "41it [00:01, 25.10it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01 19:30:00\n",
      "2008-01-01 20:00:00\n",
      "2008-01-01 20:30:00\n",
      "2008-01-01 21:00:00\n",
      "2008-01-01 21:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "44it [00:01, 24.73it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01 22:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [04:15,  2.61s/it]\n",
      "\n",
      "\n",
      "47it [00:02, 14.80it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-01 22:30:00\n",
      "2008-01-01 23:00:00\n",
      "2008-01-01 23:30:00\n",
      "2008-01-02 00:00:00\n",
      "2008-01-02 00:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:02, 17.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "53it [00:02, 19.33it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-02 01:00:00\n",
      "2008-01-02 01:30:00\n",
      "2008-01-02 02:00:00\n",
      "2008-01-02 02:30:00\n",
      "2008-01-02 03:00:00\n",
      "2008-01-02 03:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "56it [00:02, 21.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "59it [00:02, 22.70it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-02 04:00:00\n",
      "2008-01-02 04:30:00\n",
      "2008-01-02 05:00:00\n",
      "2008-01-02 05:30:00\n",
      "2008-01-02 06:00:00\n",
      "2008-01-02 06:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "62it [00:02, 23.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "65it [00:02, 24.84it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-02 07:00:00\n",
      "2008-01-02 07:30:00\n",
      "2008-01-02 08:00:00\n",
      "2008-01-02 08:30:00\n",
      "2008-01-02 09:00:00\n",
      "2008-01-02 09:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "68it [00:02, 25.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "71it [00:02, 26.05it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-02 10:00:00\n",
      "2008-01-02 10:30:00\n",
      "2008-01-02 11:00:00\n",
      "2008-01-02 11:30:00\n",
      "2008-01-02 12:00:00\n",
      "2008-01-02 12:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "75it [00:03, 27.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "78it [00:03, 27.70it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-02 13:00:00\n",
      "2008-01-02 13:30:00\n",
      "2008-01-02 14:00:00\n",
      "2008-01-02 14:30:00\n",
      "2008-01-02 15:00:00\n",
      "2008-01-02 15:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "81it [00:03, 27.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "84it [00:03, 26.47it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-02 16:00:00\n",
      "2008-01-02 16:30:00\n",
      "2008-01-02 17:00:00\n",
      "2008-01-02 17:30:00\n",
      "2008-01-02 18:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "87it [00:03, 25.66it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-02 18:30:00\n",
      "2008-01-02 19:00:00\n",
      "2008-01-02 19:30:00\n",
      "2008-01-02 20:00:00\n",
      "2008-01-02 20:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [00:03, 26.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "95it [00:03, 24.69it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-02 21:00:00\n",
      "2008-01-02 21:30:00\n",
      "2008-01-02 22:00:00\n",
      "2008-01-02 22:30:00\n",
      "2008-01-02 23:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_dict = {\n",
    "    # 'XGBoost0':{'xgb.XGBRegressor':{'n_jobs': 10}, 'Scaler':False, 'PCA':False},\n",
    "    # 'XGBoost1':{'xgb.XGBRegressor':{'Objective':'reg:squaredlogerror',\n",
    "    #                                'n_estimator':100,\n",
    "    #                                # 'eval_metric':'mape',\n",
    "    #                                'booster':'gbtree',\n",
    "    #                                'verbosity':0,\n",
    "    #                                # 'disable_default_eval_metric':'false',\n",
    "    #                                'learning_rate':0.2,\n",
    "    #                                'max_depth':7,\n",
    "    #                                'min_child_weight':2,\n",
    "    #                                'sampling_method':'gradient_based',\n",
    "    #                                'n_jobs': 10}, 'Scaler':False, 'PCA':False},\n",
    "    #'ElasticNet':{'ElasticNet':{'alpha':1.0, 'l1_ratio':0.5}},\n",
    "    #'ElasticNet_2':{'ElasticNet':None},\n",
    "    #'Lasso':{'Lasso':None},\n",
    "    'RandomForest':{'RandomForestRegressor':{'n_jobs': 4}, 'Scaler':False, 'PCA':False},\n",
    "    # 'RandomForest_2':{'RandomForestRegressor':{'n_estimators': 300, 'min_samples_split': 10,\n",
    "    #                                         'min_samples_leaf': 1, 'max_features': 'sqrt','max_depth': 40,\n",
    "    #                                       'bootstrap': False, 'n_jobs': 10}, 'Scaler':False, 'PCA':False},\n",
    "    #                'AdaBoost':{'AdaBoostRegressor':None},\n",
    "    # 'SVR0':{'SVR':None, 'Scaler':'StandardScaler', 'PCA':5},\n",
    "    # 'SVR1':{'SVR':None, 'Scaler':'StandardScaler', 'PCA':9},\n",
    "    # 'SVR2':{'SVR':None, 'Scaler':'StandardScaler', 'PCA':10},\n",
    "    # 'HuberRegressor':{'HuberRegressor':{'epsilon':1.0, 'max_iter':200*20, 'alpha':0.0001}, 'Scaler':False, 'PCA':False},\n",
    "    # 'HuberRegressor1':{'HuberRegressor':None, 'Scaler':'StandardScaler', 'PCA':9},\n",
    "    # 'HuberRegressor2':{'HuberRegressor':None, 'Scaler':False, 'PCA':9},\n",
    "    # 'HuberRegressor2':{'HuberRegressor':{'epsilon':1.0, 'max_iter':200*20, 'alpha':1e-10}, 'Scaler':False, 'PCA':9},\n",
    "    # 'HuberRegressor3':{'HuberRegressor':None, 'Scaler':'StandardScaler', 'PCA':9},\n",
    "    # 'HuberRegresso4':{'HuberRegressor':{'epsilon':1.0, 'max_iter':200*20, 'alpha':1e-10}, 'Scaler':'StandardScaler', 'PCA':9},\n",
    "    # 'HuberRegressor5':{'HuberRegressor':None, 'Scaler':'StandardScaler', 'PCA':9},\n",
    "    # 'SVR2':{'SVR':None, 'Scaler':'RobustScaler', 'PCA':6},\n",
    "    #'KNR':{'neighbors.KNeighborsRegressor':None},\n",
    "    #'BaggingRegressor':{'BaggingRegressor':None},\n",
    "    #'GradientBoosting':{'GradientBoostingRegressor':None},\n",
    "}\n",
    "\n",
    "df_resultados = pd.DataFrame()\n",
    "\n",
    "for modelo in models_dict.items():\n",
    "    #print(modelo, type(modelo))\n",
    "    try:\n",
    "        output_name_model = modelo[0]\n",
    "        name_model = list(modelo[1])[0]\n",
    "        params = modelo[1].get(name_model)\n",
    "        scaler = modelo[1]['Scaler']\n",
    "        pca = modelo[1]['PCA']\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        print(\"\\n\\n--->\", output_name_model, '<--- hora inicio:', start_time)\n",
    "        print(\"Parametros: \", params, \" scaler: \", scaler, \" pca: \", pca)\n",
    "        nombre = output_name_model + '_' + NOM_EXP + '_' + start_time.strftime('%Y_%m_%d-%H_%M') + '.csv'\n",
    "        print(nombre)\n",
    "        resultados = backtest_regression(name_model, inicial_date, end_date, df, cutoff, retrain_days,\n",
    "                                         scaler, pca, params)\n",
    "        # print(\"mean absolute porcentage error:\", mean_absolute_porcentage_error(resultados))\n",
    "        # print(\"mean absolute error:\", mean_absolute_error(resultados))\n",
    "        # print(\"root mean square error:\", root_mean_square_error(resultados))\n",
    "        # print(\"tiempo de ejecucion: \", datetime.now() - start_time)\n",
    "        # resultados.to_csv(PATH + nombre, index = False, header=True)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\":::::::::::  Error en \" + modelo[0], \" ::: \", ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
