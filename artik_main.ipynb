{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Artik 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17785751376919860730\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2255906407\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17428994458375981652\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import neighbors\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import *\n",
    "# import catboost as ctb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01 06:00:00</td>\n",
       "      <td>1.95817</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-01 06:30:00</td>\n",
       "      <td>1.95815</td>\n",
       "      <td>1651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-01 07:00:00</td>\n",
       "      <td>1.95824</td>\n",
       "      <td>1352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-01 07:30:00</td>\n",
       "      <td>1.95822</td>\n",
       "      <td>1722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-01 08:00:00</td>\n",
       "      <td>1.95852</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193895</th>\n",
       "      <td>2022-07-13 03:30:00</td>\n",
       "      <td>1.18863</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193896</th>\n",
       "      <td>2022-07-13 04:00:00</td>\n",
       "      <td>1.18813</td>\n",
       "      <td>1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193897</th>\n",
       "      <td>2022-07-13 04:30:00</td>\n",
       "      <td>1.18794</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193898</th>\n",
       "      <td>2022-07-13 05:00:00</td>\n",
       "      <td>1.18797</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193899</th>\n",
       "      <td>2022-07-13 05:30:00</td>\n",
       "      <td>1.18774</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Time    Close  Volume\n",
       "0      2007-01-01 06:00:00  1.95817    1728\n",
       "1      2007-01-01 06:30:00  1.95815    1651\n",
       "2      2007-01-01 07:00:00  1.95824    1352\n",
       "3      2007-01-01 07:30:00  1.95822    1722\n",
       "4      2007-01-01 08:00:00  1.95852    1729\n",
       "...                    ...      ...     ...\n",
       "193895 2022-07-13 03:30:00  1.18863     596\n",
       "193896 2022-07-13 04:00:00  1.18813    1522\n",
       "193897 2022-07-13 04:30:00  1.18794    1852\n",
       "193898 2022-07-13 05:00:00  1.18797    1404\n",
       "193899 2022-07-13 05:30:00  1.18774    1175\n",
       "\n",
       "[193900 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbpusd = pd.read_csv(f'~\\Documents\\Artik_47\\Artik-47\\data\\GBPUSD_M30.csv', sep='\\t', parse_dates=['Time'])\n",
    "\n",
    "#Just for close values as objetive\n",
    "gbpusd = gbpusd[['Time', 'Close', 'Volume']]\n",
    "gbpusd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>193900.000000</td>\n",
       "      <td>193900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.513250</td>\n",
       "      <td>5233.197968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.215370</td>\n",
       "      <td>11369.920694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.142930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.322348</td>\n",
       "      <td>1562.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.517765</td>\n",
       "      <td>2935.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.613150</td>\n",
       "      <td>5508.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.114250</td>\n",
       "      <td>556867.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Close         Volume\n",
       "count  193900.000000  193900.000000\n",
       "mean        1.513250    5233.197968\n",
       "std         0.215370   11369.920694\n",
       "min         1.142930       1.000000\n",
       "25%         1.322348    1562.000000\n",
       "50%         1.517765    2935.000000\n",
       "75%         1.613150    5508.000000\n",
       "max         2.114250  556867.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbpusd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Close_1</th>\n",
       "      <th>Close_2</th>\n",
       "      <th>Close_3</th>\n",
       "      <th>Close_4</th>\n",
       "      <th>Close_5</th>\n",
       "      <th>var_last_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-01-01 08:30:00</td>\n",
       "      <td>1.95877</td>\n",
       "      <td>1524</td>\n",
       "      <td>1.95852</td>\n",
       "      <td>1.95822</td>\n",
       "      <td>1.95824</td>\n",
       "      <td>1.95815</td>\n",
       "      <td>1.95817</td>\n",
       "      <td>2.245000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-01-01 09:00:00</td>\n",
       "      <td>1.95882</td>\n",
       "      <td>1565</td>\n",
       "      <td>1.95877</td>\n",
       "      <td>1.95852</td>\n",
       "      <td>1.95822</td>\n",
       "      <td>1.95824</td>\n",
       "      <td>1.95815</td>\n",
       "      <td>6.745000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007-01-01 09:30:00</td>\n",
       "      <td>1.95883</td>\n",
       "      <td>1704</td>\n",
       "      <td>1.95882</td>\n",
       "      <td>1.95877</td>\n",
       "      <td>1.95852</td>\n",
       "      <td>1.95822</td>\n",
       "      <td>1.95824</td>\n",
       "      <td>8.018000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007-01-01 10:00:00</td>\n",
       "      <td>1.95840</td>\n",
       "      <td>1643</td>\n",
       "      <td>1.95883</td>\n",
       "      <td>1.95882</td>\n",
       "      <td>1.95877</td>\n",
       "      <td>1.95852</td>\n",
       "      <td>1.95822</td>\n",
       "      <td>6.897000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2007-01-01 10:30:00</td>\n",
       "      <td>1.95823</td>\n",
       "      <td>1358</td>\n",
       "      <td>1.95840</td>\n",
       "      <td>1.95883</td>\n",
       "      <td>1.95882</td>\n",
       "      <td>1.95877</td>\n",
       "      <td>1.95852</td>\n",
       "      <td>3.837000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193895</th>\n",
       "      <td>2022-07-13 03:30:00</td>\n",
       "      <td>1.18863</td>\n",
       "      <td>596</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>1.18834</td>\n",
       "      <td>1.18883</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>1.18866</td>\n",
       "      <td>4.823000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193896</th>\n",
       "      <td>2022-07-13 04:00:00</td>\n",
       "      <td>1.18813</td>\n",
       "      <td>1522</td>\n",
       "      <td>1.18863</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>1.18834</td>\n",
       "      <td>1.18883</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>4.910000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193897</th>\n",
       "      <td>2022-07-13 04:30:00</td>\n",
       "      <td>1.18794</td>\n",
       "      <td>1852</td>\n",
       "      <td>1.18813</td>\n",
       "      <td>1.18863</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>1.18834</td>\n",
       "      <td>1.18883</td>\n",
       "      <td>9.878000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193898</th>\n",
       "      <td>2022-07-13 05:00:00</td>\n",
       "      <td>1.18797</td>\n",
       "      <td>1404</td>\n",
       "      <td>1.18794</td>\n",
       "      <td>1.18813</td>\n",
       "      <td>1.18863</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>1.18834</td>\n",
       "      <td>1.352700e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193899</th>\n",
       "      <td>2022-07-13 05:30:00</td>\n",
       "      <td>1.18774</td>\n",
       "      <td>1175</td>\n",
       "      <td>1.18797</td>\n",
       "      <td>1.18794</td>\n",
       "      <td>1.18813</td>\n",
       "      <td>1.18863</td>\n",
       "      <td>1.18885</td>\n",
       "      <td>1.696800e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193895 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Time    Close  Volume  Close_1  Close_2  Close_3  \\\n",
       "5      2007-01-01 08:30:00  1.95877    1524  1.95852  1.95822  1.95824   \n",
       "6      2007-01-01 09:00:00  1.95882    1565  1.95877  1.95852  1.95822   \n",
       "7      2007-01-01 09:30:00  1.95883    1704  1.95882  1.95877  1.95852   \n",
       "8      2007-01-01 10:00:00  1.95840    1643  1.95883  1.95882  1.95877   \n",
       "9      2007-01-01 10:30:00  1.95823    1358  1.95840  1.95883  1.95882   \n",
       "...                    ...      ...     ...      ...      ...      ...   \n",
       "193895 2022-07-13 03:30:00  1.18863     596  1.18885  1.18834  1.18883   \n",
       "193896 2022-07-13 04:00:00  1.18813    1522  1.18863  1.18885  1.18834   \n",
       "193897 2022-07-13 04:30:00  1.18794    1852  1.18813  1.18863  1.18885   \n",
       "193898 2022-07-13 05:00:00  1.18797    1404  1.18794  1.18813  1.18863   \n",
       "193899 2022-07-13 05:30:00  1.18774    1175  1.18797  1.18794  1.18813   \n",
       "\n",
       "        Close_4  Close_5  var_last_val  \n",
       "5       1.95815  1.95817  2.245000e-08  \n",
       "6       1.95824  1.95815  6.745000e-08  \n",
       "7       1.95822  1.95824  8.018000e-08  \n",
       "8       1.95852  1.95822  6.897000e-08  \n",
       "9       1.95877  1.95852  3.837000e-08  \n",
       "...         ...      ...           ...  \n",
       "193895  1.18885  1.18866  4.823000e-08  \n",
       "193896  1.18883  1.18885  4.910000e-08  \n",
       "193897  1.18834  1.18883  9.878000e-08  \n",
       "193898  1.18885  1.18834  1.352700e-07  \n",
       "193899  1.18863  1.18885  1.696800e-07  \n",
       "\n",
       "[193895 rows x 9 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = gbpusd.copy()\n",
    "\n",
    "#Shift last x values\n",
    "last_x = 6\n",
    "\n",
    "list_shift = []\n",
    "for i in range(1,last_x):\n",
    "    name_col = 'Close_' + str(i)\n",
    "    df[name_col] = df['Close'].shift(i)\n",
    "    list_shift.append(name_col)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "#Variance of shift values\n",
    "df['var_last_val'] = df[list_shift].var(axis=1)\n",
    "\n",
    "\n",
    "#Spit\n",
    "# X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ML  version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def backtest_regression(model_name, fecha_inicio, fecha_fin, data, cutoff, retrain_days, t_scaler, n_pca, params=None):\n",
    "    #print(\"from: \", fecha_inicio, \" to: \", fecha_fin)\n",
    "\n",
    "    #Primer entreno\n",
    "    mask = (data.ds < (fecha_inicio - timedelta(days=cutoff)))\n",
    "    train = data.loc[mask]\n",
    "    #print(\"Train: \\n\", train.iloc[:,0:6], \"\\n\")\n",
    "    train = train.drop(columns=['ds'])\n",
    "\n",
    "    val_reales = np.array([])\n",
    "    val_pred = np.array([])\n",
    "    val_fechas = np.array([])\n",
    "\n",
    "    # Divide en variables de entrada y salida\n",
    "    X, y = train.values[:, 1:], train.values[:, 0].astype('float64')\n",
    "\n",
    "    #Scalers\n",
    "    if(t_scaler=='MinMaxScaler'):\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        X = scaler.fit_transform(X)\n",
    "    elif(t_scaler=='StandardScaler'):\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "    elif(t_scaler=='RobustScaler'):\n",
    "        scaler = RobustScaler(quantile_range=(0, 95.0))\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "    #PCA\n",
    "    if (type(n_pca) == int):\n",
    "        pca = PCA(n_components=n_pca)\n",
    "        X = pca.fit_transform(X)\n",
    "\n",
    "    #Crea el modelo\n",
    "    model = eval(model_name + \"()\")\n",
    "\n",
    "    #Agrega parametros\n",
    "    if(params!=None):\n",
    "        model.set_params(**params)\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "    pbar = tqdm(total=(fecha_fin-fecha_inicio).days+1)\n",
    "    fecha_index = fecha_inicio\n",
    "    while(fecha_index <= fecha_fin):\n",
    "        #print(fecha_index)\n",
    "        if(fecha_index.weekday() in retrain_days):\n",
    "\n",
    "            #Re entreno\n",
    "            mask = (data.ds < (fecha_index - timedelta(days=cutoff)))\n",
    "            train = data.loc[mask]\n",
    "            #print(\"Train: \\n\", train.iloc[:,0:6], \"\\n\")\n",
    "            train = train.drop(columns=['ds'])\n",
    "\n",
    "            # Divide en variables de entrada y salida\n",
    "            X, y = train.values[:, 1:], train.values[:, 0].astype('float64')\n",
    "\n",
    "            #Scalers\n",
    "            if(t_scaler=='MinMaxScaler'):\n",
    "                scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "                X = scaler.fit_transform(X)\n",
    "            elif(t_scaler=='StandardScaler'):\n",
    "                scaler = StandardScaler()\n",
    "                X = scaler.fit_transform(X)\n",
    "            elif(t_scaler=='RobustScaler'):\n",
    "                scaler = RobustScaler(quantile_range=(0, 95.0))\n",
    "                X = scaler.fit_transform(X)\n",
    "\n",
    "            #PCA\n",
    "            if (type(n_pca) == int):\n",
    "                pca = PCA(n_components=n_pca)\n",
    "                X = pca.fit_transform(X)\n",
    "\n",
    "            model = eval(model_name + \"()\")\n",
    "\n",
    "            if(params!=None):\n",
    "                model.set_params(**params)\n",
    "\n",
    "            model.fit(X, y)\n",
    "\n",
    "        mask = (data.ds >= fecha_index) & (data.ds <= fecha_index + timedelta(hours=23))\n",
    "        to_pred = data.loc[mask]\n",
    "        if not(to_pred.empty):\n",
    "\n",
    "            val_fechas = np.append(val_fechas, to_pred.iloc[:,0].tolist())\n",
    "            #print(\"to_pred: \", to_pred.values)\n",
    "            to_pred = to_pred.drop(columns=['ds'])\n",
    "            # Divide en variables de entrada y salida\n",
    "            X, y = to_pred.values[:, 1:], to_pred.values[:, 0].astype('float64')\n",
    "\n",
    "            #Scalers\n",
    "            if((t_scaler=='MinMaxScaler') or (t_scaler=='StandardScaler') or (t_scaler=='RobustScaler')):\n",
    "                X = scaler.transform(X)\n",
    "\n",
    "            #PCA\n",
    "            if (type(n_pca) == int):\n",
    "                X = pca.transform(X)\n",
    "\n",
    "            y_hat = model.predict(X)\n",
    "\n",
    "            val_reales = np.append(val_reales, y)\n",
    "            val_pred = np.append(val_pred, y_hat)\n",
    "\n",
    "        fecha_index = fecha_index + timedelta(days=1)\n",
    "        pbar.update(1)\n",
    "\n",
    "    resultados = pd.DataFrame({'fechas':val_fechas, 'val_reales':val_reales, 'val_pred':val_pred})\n",
    "    pbar.close()\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    # 'XGBoost0':{'xgb.XGBRegressor':{'n_jobs': 10}, 'Scaler':False, 'PCA':False},\n",
    "    # 'XGBoost1':{'xgb.XGBRegressor':{'Objective':'reg:squaredlogerror',\n",
    "    #                                'n_estimator':100,\n",
    "    #                                # 'eval_metric':'mape',\n",
    "    #                                'booster':'gbtree',\n",
    "    #                                'verbosity':0,\n",
    "    #                                # 'disable_default_eval_metric':'false',\n",
    "    #                                'learning_rate':0.2,\n",
    "    #                                'max_depth':7,\n",
    "    #                                'min_child_weight':2,\n",
    "    #                                'sampling_method':'gradient_based',\n",
    "    #                                'n_jobs': 10}, 'Scaler':False, 'PCA':False},\n",
    "    #'ElasticNet':{'ElasticNet':{'alpha':1.0, 'l1_ratio':0.5}},\n",
    "    #'ElasticNet_2':{'ElasticNet':None},\n",
    "    #'Lasso':{'Lasso':None},\n",
    "    # 'RandomForest':{'RandomForestRegressor':{'n_jobs': 10}, 'Scaler':False, 'PCA':False},\n",
    "    # 'RandomForest_2':{'RandomForestRegressor':{'n_estimators': 300, 'min_samples_split': 10,\n",
    "    #                                         'min_samples_leaf': 1, 'max_features': 'sqrt','max_depth': 40,\n",
    "    #                                       'bootstrap': False, 'n_jobs': 10}, 'Scaler':False, 'PCA':False},\n",
    "    #                'AdaBoost':{'AdaBoostRegressor':None},\n",
    "    # 'SVR0':{'SVR':None, 'Scaler':'StandardScaler', 'PCA':5},\n",
    "    'SVR1':{'SVR':None, 'Scaler':'StandardScaler', 'PCA':9},\n",
    "    # 'SVR2':{'SVR':None, 'Scaler':'StandardScaler', 'PCA':10},\n",
    "    'HuberRegressor':{'HuberRegressor':{'epsilon':1.0, 'max_iter':200*20, 'alpha':0.0001}, 'Scaler':False, 'PCA':False},\n",
    "    'HuberRegressor1':{'HuberRegressor':None, 'Scaler':'StandardScaler', 'PCA':9},\n",
    "    'HuberRegressor2':{'HuberRegressor':None, 'Scaler':False, 'PCA':9},\n",
    "    # 'HuberRegressor2':{'HuberRegressor':{'epsilon':1.0, 'max_iter':200*20, 'alpha':1e-10}, 'Scaler':False, 'PCA':9},\n",
    "    # 'HuberRegressor3':{'HuberRegressor':None, 'Scaler':'StandardScaler', 'PCA':9},\n",
    "    # 'HuberRegresso4':{'HuberRegressor':{'epsilon':1.0, 'max_iter':200*20, 'alpha':1e-10}, 'Scaler':'StandardScaler', 'PCA':9},\n",
    "    # 'HuberRegressor5':{'HuberRegressor':None, 'Scaler':'StandardScaler', 'PCA':9},\n",
    "    # 'SVR2':{'SVR':None, 'Scaler':'RobustScaler', 'PCA':6},\n",
    "    #'KNR':{'neighbors.KNeighborsRegressor':None},\n",
    "    #'BaggingRegressor':{'BaggingRegressor':None},\n",
    "    #'GradientBoosting':{'GradientBoostingRegressor':None},\n",
    "}\n",
    "\n",
    "df_resultados = pd.DataFrame()\n",
    "\n",
    "for modelo in models_dict.items():\n",
    "    #print(modelo, type(modelo))\n",
    "    try:\n",
    "        output_name_model = modelo[0]\n",
    "        name_model = list(modelo[1])[0]\n",
    "        params = modelo[1].get(name_model)\n",
    "        scaler = modelo[1]['Scaler']\n",
    "        pca = modelo[1]['PCA']\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        print(\"\\n\\n--->\", output_name_model, '<--- hora inicio:', start_time)\n",
    "        print(\"Parametros: \", params, \" scaler: \", scaler, \" pca: \", pca)\n",
    "        nombre = output_name_model + '_' + NOM_EXP + '_' + start_time.strftime('%Y_%m_%d-%H_%M') + '.csv'\n",
    "        print(nombre)\n",
    "        resultados = backtest_regression(name_model, inicial_date, end_date, data_c, cutoff, retrain_days,\n",
    "                                         scaler, pca, params)\n",
    "        print(\"mean absolute porcentage error:\", mean_absolute_porcentage_error(resultados))\n",
    "        print(\"mean absolute error:\", mean_absolute_error(resultados))\n",
    "        print(\"root mean square error:\", root_mean_square_error(resultados))\n",
    "        print(\"tiempo de ejecucion: \", datetime.now() - start_time)\n",
    "        resultados.to_csv(PATH + nombre, index = False, header=True)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(\":::::::::::  Error en \" + modelo[0], \" ::: \", ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}